{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: /DeepLearning/mnt/shixiansheng/data_fusion/output/Test\n",
      "正在处理文件: /DeepLearning/mnt/shixiansheng/data_fusion/output/2011_Data_WithoutCV/2011_SixDataset_Daily_Metrics.csv, Period: DJF\n",
      "x_data 长度: 137241, y_data 长度: 137241\n",
      "x_data 前5个值: [nan nan nan nan nan]\n",
      "y_data 前5个值: [nan nan nan nan nan]\n",
      "x_data 中 NaN 的数量: 81656\n",
      "y_data 中 NaN 的数量: 81656\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde, linregress\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "\n",
    "# -------------------- 工具函数 --------------------\n",
    "def extract_key_period(period):\n",
    "    \"\"\"\n",
    "    Extract key period (e.g., JFM, AMJ) from the full period string.\n",
    "    \"\"\"\n",
    "    key_periods = [\"DJF\", \"MAM\", \"JJA\", \"SON\", 'Annual', 'Apr-Sep', 'top-10']\n",
    "    for key in key_periods:\n",
    "        if key in period:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_year(filename):\n",
    "    \"\"\"\n",
    "    从文件名中提取年份（假设年份在 2011 - 2020 范围内）。\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(20[1-2][0-9])\", filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_axis_label(filename, variable):\n",
    "    \"\"\"\n",
    "    根据文件名和变量生成轴标签。\n",
    "    - 如果变量为 'model'，根据文件名判断是 'Harvard ML' 还是 'EQUATES'。\n",
    "    - 其他情况根据变量名确定标签，如 'vna_ozone' 对应 'VNA'。\n",
    "    \"\"\"\n",
    "    if 'model' in variable:\n",
    "        return \"EQUATES\"\n",
    "    elif \"harvard_ml\" in variable:\n",
    "        return \"Harvard ML\"\n",
    "    elif \"evna_ozone\" in variable:\n",
    "        return \"eVNA\"\n",
    "    elif \"avna_ozone\" in variable:\n",
    "        return \"aVNA\"\n",
    "    elif \"ds_ozone\" in variable:\n",
    "        return \"Downscaler\"\n",
    "    elif \"vna_ozone\" in variable:\n",
    "        return \"VNA\"\n",
    "    elif \"Conc\" in variable:\n",
    "        return \"Monitor\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "# -------------------- 定义绘图函数 --------------------\n",
    "def plot_density_scatter(dataframe_x, dataframe_y, x_column, y_column, period_column, output_dir, period_value, file_name, output_csv_path):\n",
    "    \"\"\"\n",
    "    绘制散点密度图：x_column vs y_column。\n",
    "    文件名包含对应的 Period 字段。\n",
    "    \"\"\"\n",
    "    # 获取数据（通过关键字匹配 Period）\n",
    "    df_period_x = dataframe_x[dataframe_x[period_column].str.contains(period_value, case=False, na=False)]\n",
    "    df_period_y = dataframe_y[dataframe_y[period_column].str.contains(period_value, case=False, na=False)]\n",
    "\n",
    "    # 如果数据为空，跳过\n",
    "    if df_period_x.empty or df_period_y.empty:\n",
    "        print(f\"数据中没有有效数据，跳过 Period: {period_value} 的绘图。\")\n",
    "        return\n",
    "\n",
    "    # 获取数据\n",
    "    x_data = df_period_x[x_column].values\n",
    "    y_data = df_period_y[y_column].values\n",
    "\n",
    "    # 打印正在处理的数据信息\n",
    "    print(f\"正在处理文件: {file_name}, Period: {period_value}\")\n",
    "    print(f\"x_data 长度: {len(x_data)}, y_data 长度: {len(y_data)}\")\n",
    "    print(f\"x_data 前5个值: {x_data[:5]}\")\n",
    "    print(f\"y_data 前5个值: {y_data[:5]}\")\n",
    "    print(f\"x_data 中 NaN 的数量: {np.isnan(x_data).sum()}\")\n",
    "    print(f\"y_data 中 NaN 的数量: {np.isnan(y_data).sum()}\")\n",
    "\n",
    "    # 核密度计算\n",
    "    valid_indices = ~np.isnan(x_data) & ~np.isnan(y_data)\n",
    "    valid_x_data = x_data[valid_indices]\n",
    "    valid_y_data = y_data[valid_indices]\n",
    "\n",
    "    if len(valid_x_data) == 0 or len(valid_y_data) == 0:\n",
    "        print(f\"数据为空，跳过 Period: {period_value} 的绘图。\")\n",
    "        return\n",
    "\n",
    "    # 获取文件名的基名\n",
    "    file_base_name = os.path.basename(file_name).split(\".\")[0]\n",
    "\n",
    "    # 提取年份\n",
    "    year = get_year(file_name)\n",
    "\n",
    "    # 只提取季节和年份部分\n",
    "    period_search = extract_key_period(period_value)\n",
    "    if period_search:\n",
    "        period_value = period_search\n",
    "\n",
    "    # 拼接成期望的格式，如：2011_JAS\n",
    "    formatted_period = f\"{year}_{period_value}\"\n",
    "\n",
    "    # 生成轴标签\n",
    "    x_label = get_axis_label(x_axis_file, x_column)  # x 轴标签\n",
    "    y_label = get_axis_label(file_name, y_column)  # y 轴标签\n",
    "\n",
    "    full_title = f\"{formatted_period}: {y_label} vs. {x_label}\"\n",
    "\n",
    "    # 核密度计算\n",
    "    xy = np.vstack([valid_x_data, valid_y_data])\n",
    "    kde = gaussian_kde(xy)\n",
    "    z = kde(xy)\n",
    "    z = (z - z.min()) / (z.max() - z.min())  # 归一化\n",
    "\n",
    "    # 绘制散点密度图\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    scatter = ax.scatter(valid_x_data, valid_y_data, c=z, cmap='jet', s=20, alpha=0.8)\n",
    "    fig.colorbar(scatter, ax=ax)  # 删除了 label 参数\n",
    "\n",
    "    # 添加 1:1 参考线\n",
    "    max_val = max(valid_x_data.max(), valid_y_data.max())\n",
    "    max_val =116  # 设置最大值为 116\n",
    "\n",
    "    # 调整x和y轴一样并添加余量，如果数据差别不大\n",
    "    max_val1 = max_val + 3\n",
    "    ax.set_xlim(-3, max_val1)\n",
    "    ax.set_ylim(-3, max_val1)\n",
    "\n",
    "    ax.plot([-3, max_val1], [-3, max_val1], 'b--', lw=0.5)  # 蓝色 1:1 线\n",
    "\n",
    "    # 添加回归线\n",
    "    slope, intercept, r_value, _, _ = linregress(valid_x_data, valid_y_data)\n",
    "    r_squared = r_value ** 2\n",
    "    mb = np.mean(valid_y_data - valid_x_data)  # 计算 MB (平均偏差)\n",
    "\n",
    "    # 计算 RMSE\n",
    "    rmse = np.sqrt(np.mean((valid_y_data - valid_x_data) ** 2))  # 计算 RMSE\n",
    "\n",
    "    # 调整回归线方程格式\n",
    "    if intercept >= 0:\n",
    "        regression_equation = fr\"$y = {slope:.2f}\\it{{x}} + {intercept:.2f}$\"\n",
    "    else:\n",
    "        regression_equation = fr\"$y = {slope:.2f}\\it{{x}} {intercept:.2f}$\"\n",
    "\n",
    "    # 将 R²、MB、RMSE 和拟合直线方程添加到左上角\n",
    "    r_squared = round(r_squared, 2)\n",
    "    mb = round(mb, 2)\n",
    "    rmse = round(rmse, 2)\n",
    "\n",
    "    # 绘制回归线（红色）\n",
    "    regression_line = slope * np.array([0, max_val]) + intercept\n",
    "    ax.plot([0, max_val], regression_line, 'r-', lw=0.5, label=\"Regression Line\")\n",
    "    slope = round(slope, 2)\n",
    "    # 将统计信息添加到左上角\n",
    "    ax.text(0.05, 0.95, f\"$R^2$ = {r_squared:.2f}\\nMB = {mb}\\nRMSE = {rmse}\\n{regression_equation}\",\n",
    "            transform=ax.transAxes, ha=\"left\", va=\"top\", fontsize=12, fontname='Times New Roman', color='black')\n",
    "\n",
    "    # 设置标题和标签\n",
    "    ax.set_xlabel(x_label, fontsize=12, fontname='Times New Roman')  # x 轴标签\n",
    "    ax.set_ylabel(y_label, fontsize=12, fontname='Times New Roman')  # y 轴标签\n",
    "\n",
    "    # 将标题放置到图像顶部\n",
    "    fig.subplots_adjust(top=0.85)  # 调整标题的位置\n",
    "    ax.set_title(full_title, fontsize=13, loc='center', fontname='Times New Roman')\n",
    "\n",
    "    # 保存图像，文件名包含 Period 字段和输入文件名（不含路径）\n",
    "    output_file_name = f'{full_title}.png'\n",
    "    output_path = os.path.join(output_dir, output_file_name)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"散点密度图已保存至 {output_path}\")\n",
    "\n",
    "    # 将计算结果添加到表格中\n",
    "    variable_pair = f\"{y_label} vs. {x_label}\"\n",
    "    result_dict = {\n",
    "        'Variable Pair': variable_pair,\n",
    "        'Period': formatted_period,\n",
    "        'R_squared': r_squared,\n",
    "        'RMSE': rmse,\n",
    "        'MB': mb,\n",
    "        'Slope': slope,\n",
    "    }\n",
    "    result_df = pd.DataFrame([result_dict])\n",
    "    if not os.path.exists(output_csv_path):\n",
    "        result_df.to_csv(output_csv_path, index=False)\n",
    "    else:\n",
    "        result_df.to_csv(output_csv_path, mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "# -------------------- 读取和处理多个文件 --------------------\n",
    "def process_file(fusion_output_file, x_axis_file):\n",
    "    # 读取第一个文件的数据（y 轴数据）\n",
    "    df_data_y = pd.read_csv(fusion_output_file)\n",
    "\n",
    "    # 读取第二个文件的数据（x 轴数据）\n",
    "    df_data_x = pd.read_csv(x_axis_file)\n",
    "\n",
    "    # 提取Period列\n",
    "    period_column = 'Period'  # Period列\n",
    "\n",
    "    # variables = ['model', 'vna_ozone', 'evna_ozone', 'avna_ozone', 'ds_ozone', 'harvard_ml']\n",
    "    # comparisons = list(itertools.combinations(variables, 2))\n",
    "    # comparisons = [('model','model'),('vna_ozone','vna_ozone'),('avna_ozone','avna_ozone')]\n",
    "    comparisons = [('model','vna_ozone'),('model','evna_ozone'),('model','avna_ozone')]\n",
    "    keywords = ['DJF','MAM','JJA','SON','Apr-Sep','Annual','top-10']\n",
    "\n",
    "    # 提取年份\n",
    "    year_x = get_year(x_axis_file)\n",
    "    year_y = get_year(fusion_output_file)\n",
    "\n",
    "    if year_x != year_y:\n",
    "        print(\"Warning: The years in the input files do not match!\")\n",
    "        return\n",
    "\n",
    "    year = year_x\n",
    "\n",
    "    # 动态生成路径名称\n",
    "    output_dir = os.path.join('/DeepLearning/mnt/shixiansheng/data_fusion/output', f\"{year}_CompareScatter\")\n",
    "\n",
    "    # 如果路径不存在，则自动创建\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created directory: {output_dir}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {output_dir}\")\n",
    "\n",
    "    output_csv_path = os.path.join(output_dir, '2011_MethodCompareTable.csv')\n",
    "\n",
    "    # 遍历每个关键字并绘制图形\n",
    "    for keyword in keywords:\n",
    "        for x_column, y_column in comparisons:\n",
    "            plot_density_scatter(df_data_x, df_data_y, x_column, y_column, period_column, output_dir, keyword,\n",
    "                                 fusion_output_file, output_csv_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件\n",
    "    # fusion_output_files = [\n",
    "    #     \"/DeepLearning/mnt/shixiansheng/data_fusion/output/2011_Data_WithoutCV/2011_SixDataset_CONUS_dailyIntometrics.csv\",\n",
    "    # ]\n",
    "    # x_axis_file = \"/DeepLearning/mnt/shixiansheng/data_fusion/output/2011_Data_WithoutCV/2011_SixDataset_CONUS_dailyIntometrics.csv\"\n",
    "\n",
    "    fusion_output_files = [\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/2011_Data_WithoutCV/2011_HourlyMetrics_Trans.csv\",\n",
    "    ]\n",
    "    x_axis_file = \"/DeepLearning/mnt/shixiansheng/data_fusion/output/2011_Data_WithoutCV/2011_HourlyMetrics_Trans.csv\"\n",
    "\n",
    "    for file in fusion_output_files:\n",
    "        process_file(file, x_axis_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
