{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# HourlyFullCheck\n",
    "# file_path = '/backupdata/data_EPA/aq_obs/routine/2011/AQS_hourly_data_2011_LatLon.csv'\n",
    "# complete_count = 0  # 用于统计完整数据的数量\n",
    "# incomplete_count = 0  # 用于统计不完整数据的数量\n",
    "# try:\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     # 将 dateon 列转换为日期时间类型\n",
    "#     df['dateon'] = pd.to_datetime(df['dateon'])\n",
    "\n",
    "#     # 提取日期和小时信息\n",
    "#     df['date'] = df['dateon'].dt.date\n",
    "#     df['hour'] = df['dateon'].dt.hour\n",
    "\n",
    "#     # 按站点 ID 和日期分组\n",
    "#     grouped = df.groupby(['site_id', 'date'])\n",
    "\n",
    "#     # 检查每组是否有 24 个小时的数据\n",
    "#     for (site_id, date), group in grouped:\n",
    "#         if len(group['hour'].unique()) == 24:\n",
    "#             complete_count += 1\n",
    "#         else:\n",
    "#             incomplete_count += 1\n",
    "\n",
    "#     print(f\"有完整 24 小时数据的站点-日期组合数量: {complete_count}\")\n",
    "#     print(f\"数据不完整的站点-日期组合数量: {incomplete_count}\")\n",
    "\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"错误: 文件 {file_path} 未找到。\")\n",
    "# except Exception as e:\n",
    "#     print(f\"发生未知错误: {e}\")\n",
    "# from itertools import product\n",
    "\n",
    "# #2011年输出\n",
    "# # 有完整 24 小时数据的站点-日期组合数量: 246920\n",
    "# # 数据不完整的站点-日期组合数量: 136149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "周期 DJF 的唯一站点数量: 1330\n",
      "周期 MAM 的唯一站点数量: 1330\n",
      "周期 JJA 的唯一站点数量: 1330\n",
      "周期 SON 的唯一站点数量: 1330\n",
      "周期 Apr - Sep 的唯一站点数量: 1330\n",
      "周期 Annual 的唯一站点数量: 1330\n",
      "结果已保存到 /backupdata/data_EPA/aq_obs/routine/2011/AQS_hourly_data_2011_LatLon_MissingHours.csv\n",
      "周期 DJF 中缺失小时数最大的站点信息：\n",
      "     Period    site_id        Lat         Lon  MissingHours\n",
      "0       DJF   10030010  30.497478  -87.880258          2160\n",
      "1       DJF   10331002  34.762619  -87.638097          2160\n",
      "3       DJF   10510001  32.498567  -86.136587          2160\n",
      "4       DJF   10550011  33.904039  -86.053867          2160\n",
      "5       DJF   10690004  31.188933  -85.423094          2160\n",
      "...     ...        ...        ...         ...           ...\n",
      "1288    DJF  551250001  46.051900  -89.654000          2160\n",
      "1289    DJF  551270005  42.580009  -88.499046          2160\n",
      "1290    DJF  551330027  43.020075  -88.215070          2160\n",
      "1297    DJF  560111013  44.596900 -104.704800          2160\n",
      "1302    DJF  560252601  42.860800 -106.235860          2160\n",
      "\n",
      "[516 rows x 5 columns]\n",
      "周期 MAM 中缺失小时数最大的站点信息：\n",
      "     Period    site_id        Lat         Lon  MissingHours\n",
      "1346    MAM   10890022  34.772727  -86.756174          2208\n",
      "1357    MAM   20900034  64.845690 -147.727413          2208\n",
      "1436    MAM   60231005  40.715280 -124.201390          2208\n",
      "1468    MAM   60390500  37.213600 -119.699065          2208\n",
      "1474    MAM   60431005  37.730717 -119.571554          2208\n",
      "1489    MAM   60610003  38.935680 -121.099590          2208\n",
      "1494    MAM   60650009  33.447867 -117.088649          2208\n",
      "1529    MAM   60719010  34.193925 -116.914063          2208\n",
      "1581    MAM   60971003  38.654069 -122.901857          2208\n",
      "1604    MAM   80130007  39.941000 -105.612000          2208\n",
      "1607    MAM   80190004  39.643000 -105.592000          2208\n",
      "1608    MAM   80190005  39.587000 -105.641000          2208\n",
      "1615    MAM   80450014  39.799000 -107.617000          2208\n",
      "1616    MAM   80450015  40.085000 -107.312000          2208\n",
      "1619    MAM   80510008  39.090000 -107.234000          2208\n",
      "1621    MAM   80570003  40.882222 -106.306111          2208\n",
      "1635    MAM   80770021  38.930000 -108.230000          2208\n",
      "1638    MAM   80810002  40.506946 -107.891109          2208\n",
      "1685    MAM  120350004  29.489083  -81.276833          2208\n",
      "1914    MAM  220870009  29.936909  -89.955703          2208\n",
      "2420    MAM  470930021  36.085508  -83.764806          2208\n",
      "2421    MAM  470931020  36.019186  -83.873810          2208\n",
      "2522    MAM  490170004  37.775556 -111.614722          2208\n",
      "2527    MAM  490470014  40.538000 -109.700000          2208\n",
      "2625    MAM  560050800  44.265833 -105.504167          2208\n",
      "2632    MAM  560252601  42.860800 -106.235860          2208\n",
      "2643    MAM  560370870  41.588717 -109.760975          2208\n",
      "2644    MAM  560390008  43.670833 -110.599472          2208\n",
      "2656    MAM  800020018  32.570278 -115.448611          2208\n",
      "周期 JJA 中缺失小时数最大的站点信息：\n",
      "     Period    site_id        Lat         Lon  MissingHours\n",
      "2813    JJA   60571001  39.327830 -120.184592          2208\n",
      "2822    JJA   60650004  34.007000 -117.521000          2208\n",
      "2859    JJA   60719010  34.193925 -116.914063          2208\n",
      "2868    JJA   60731011  32.725226 -116.365203          2208\n",
      "2927    JJA   61112003  34.280401 -119.314557          2208\n",
      "2951    JJA   80570003  40.882222 -106.306111          2208\n",
      "3244    JJA  220870009  29.936909  -89.955703          2208\n",
      "3852    JJA  490170004  37.775556 -111.614722          2208\n",
      "3955    JJA  560050800  44.265833 -105.504167          2208\n",
      "3982    JJA  800020005  32.500000 -117.116667          2208\n",
      "3983    JJA  800020012  32.629167 -115.446944          2208\n",
      "3986    JJA  800020018  32.570278 -115.448611          2208\n",
      "周期 SON 中缺失小时数最大的站点信息：\n",
      "     Period    site_id        Lat         Lon  MissingHours\n",
      "4143    SON   60571001  39.327830 -120.184592          2184\n",
      "4148    SON   60610002  38.937778 -121.103889          2184\n",
      "4152    SON   60650004  34.007000 -117.521000          2184\n",
      "4189    SON   60719010  34.193925 -116.914063          2184\n",
      "4198    SON   60731011  32.725226 -116.365203          2184\n",
      "4257    SON   61112003  34.280401 -119.314557          2184\n",
      "4309    SON   90010017  41.004657  -73.585128          2184\n",
      "4412    SON  160010010  43.600699 -116.347853          2184\n",
      "4517    SON  201730001  37.781401  -97.337543          2184\n",
      "4574    SON  220870009  29.936909  -89.955703          2184\n",
      "4833    SON  360930003  42.799010  -73.938900          2184\n",
      "4983    SON  420010002  39.930000  -77.250000          2184\n",
      "5173    SON  484790016  27.507904  -99.523949          2184\n",
      "5182    SON  490170004  37.775556 -111.614722          2184\n",
      "5193    SON  490495008  40.430278 -111.803889          2184\n",
      "5311    SON  800020004  32.343333 -117.054722          2184\n",
      "5312    SON  800020005  32.500000 -117.116667          2184\n",
      "5313    SON  800020012  32.629167 -115.446944          2184\n",
      "5316    SON  800020018  32.570278 -115.448611          2184\n",
      "周期 Apr - Sep 中缺失小时数最大的站点信息：\n",
      "         Period    site_id        Lat         Lon  MissingHours\n",
      "5519  Apr - Sep   60719010  34.193925 -116.914063          4392\n",
      "5611  Apr - Sep   80570003  40.882222 -106.306111          4392\n",
      "5904  Apr - Sep  220870009  29.936909  -89.955703          4392\n",
      "6512  Apr - Sep  490170004  37.775556 -111.614722          4392\n",
      "6615  Apr - Sep  560050800  44.265833 -105.504167          4392\n",
      "6642  Apr - Sep  800020005  32.500000 -117.116667          4392\n",
      "6643  Apr - Sep  800020012  32.629167 -115.446944          4392\n",
      "6646  Apr - Sep  800020018  32.570278 -115.448611          4392\n",
      "周期 Annual 中缺失小时数最大的站点信息：\n",
      "      Period    site_id        Lat         Lon  MissingHours\n",
      "7842  Annual  490170004  37.775556 -111.614722          8385\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CalMissingHour\n",
    "def print_unique_sites_count():\n",
    "    try:\n",
    "        # 读取输入文件\n",
    "        input_file_path = '/backupdata/data_EPA/aq_obs/routine/2011/AQS_hourly_data_2011_LatLon.csv'\n",
    "        input_df = pd.read_csv(input_file_path)\n",
    "        input_df['dateon'] = pd.to_datetime(input_df['dateon'])\n",
    "\n",
    "        # 获取所有唯一的站点信息\n",
    "        all_sites = input_df.groupby('site_id').first()[['Lat', 'Lon']]\n",
    "\n",
    "        periods = {\n",
    "            'DJF': pd.date_range('2011-01-01 00:00:00', '2011-02-28 23:00:00', freq='H').union(\n",
    "                pd.date_range('2011-12-01 00:00:00', '2011-12-31 23:00:00', freq='H')),\n",
    "            'MAM': pd.date_range('2011-03-01 00:00:00', '2011-05-31 23:00:00', freq='H'),\n",
    "            'JJA': pd.date_range('2011-06-01 00:00:00', '2011-08-31 23:00:00', freq='H'),\n",
    "            'SON': pd.date_range('2011-09-01 00:00:00', '2011-11-30 23:00:00', freq='H'),\n",
    "            'Apr - Sep': pd.date_range('2011-04-01 00:00:00', '2011-09-30 23:00:00', freq='H'),\n",
    "            'Annual': pd.date_range('2011-01-01 00:00:00', '2011-12-31 23:00:00', freq='H'),\n",
    "        }\n",
    "\n",
    "        results = []\n",
    "        for period_name, period_dates in periods.items():\n",
    "            all_hours_count = len(period_dates)\n",
    "            # 按站点分组，使用向量化操作计算每个站点在该周期内的现有小时数\n",
    "            period_df = input_df[input_df['dateon'].isin(period_dates)]\n",
    "            if not period_df.empty:\n",
    "                site_grouped = period_df.groupby('site_id')\n",
    "                existing_hours = site_grouped['dateon'].nunique()\n",
    "            else:\n",
    "                existing_hours = pd.Series([0] * len(all_sites), index=all_sites.index)\n",
    "\n",
    "            # 计算所有站点的缺失小时数\n",
    "            missing_hours = all_hours_count - existing_hours.reindex(all_sites.index, fill_value=0)\n",
    "            # 创建该周期的结果 DataFrame\n",
    "            period_result = pd.DataFrame({\n",
    "                'Period': period_name,\n",
    "                'site_id': all_sites.index,\n",
    "                'Lat': all_sites['Lat'],\n",
    "                'Lon': all_sites['Lon'],\n",
    "                'MissingHours': missing_hours\n",
    "            })\n",
    "            results.append(period_result)\n",
    "\n",
    "            # 打印该周期的唯一站点数量\n",
    "            unique_sites_count = len(period_result['site_id'].unique())\n",
    "            print(f\"周期 {period_name} 的唯一站点数量: {unique_sites_count}\")\n",
    "\n",
    "        # 合并所有周期的结果\n",
    "        if results:\n",
    "            result_df = pd.concat(results, ignore_index=True)\n",
    "            # 保存结果到输出文件\n",
    "            output_file_path = '/backupdata/data_EPA/aq_obs/routine/2011/AQS_hourly_data_2011_LatLon_MissingHours.csv'\n",
    "            result_df.to_csv(output_file_path, index=False)\n",
    "            print(f\"结果已保存到 {output_file_path}\")\n",
    "\n",
    "            # 打印每个周期缺失最大的站点\n",
    "            for period in result_df['Period'].unique():\n",
    "                period_subset = result_df[result_df['Period'] == period]\n",
    "                max_missing = period_subset[period_subset['MissingHours'] == period_subset['MissingHours'].max()]\n",
    "                print(f\"周期 {period} 中缺失小时数最大的站点信息：\")\n",
    "                print(max_missing)\n",
    "        else:\n",
    "            print(\"没有符合条件的数据，未生成结果文件。\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：未找到输入文件 {input_file_path}。\")\n",
    "    except Exception as e:\n",
    "        print(f\"发生未知错误：{e}\")\n",
    "\n",
    "\n",
    "print_unique_sites_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "#Day\n",
    "# # 加载数据\n",
    "# file_path = \"/backupdata/data_EPA/EQUATES/EQUATES_data/ds.input.aqs.o3.2011.csv\"\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# # 将 'Date' 列转换为日期时间格式\n",
    "# data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# # 定义季度函数\n",
    "# def get_quarter(month):\n",
    "#     if month in [12, 1, 2]:\n",
    "#         return 'DFJ'\n",
    "#     elif month in [3, 4, 5]:\n",
    "#         return 'MAM'\n",
    "#     elif month in [6, 7, 8]:\n",
    "#         return 'JJA'\n",
    "#     elif month in [9, 10, 11]:\n",
    "#         return 'SON'\n",
    "\n",
    "# # 添加季度列\n",
    "# data['Quarter'] = data['Date'].dt.month.apply(get_quarter)\n",
    "\n",
    "# # 生成每个季度的日期范围\n",
    "# quarters = {\n",
    "#     'DJF': pd.date_range('2011-01-01', '2011-02-28').union(pd.date_range('2011-12-01', '2011-12-31')),\n",
    "#     'MAM': pd.date_range('2011-03-01', '2011-05-31'),\n",
    "#     'JJA': pd.date_range('2011-06-01', '2011-08-31'),\n",
    "#     'SON': pd.date_range('2011-09-01', '2011-11-30'),\n",
    "#     'Apr-Sep': pd.date_range('2011-04-01', '2011-09-30'),\n",
    "#     'Annual': pd.date_range('2011-01-01', '2011-12-31'),\n",
    "# }\n",
    "\n",
    "# # 计算缺失日期的数量\n",
    "# def count_missing_dates(site_data, quarter_dates):\n",
    "#     site_quarter_data = site_data[site_data['Date'].isin(quarter_dates)]\n",
    "#     missing_dates = len(quarter_dates) - len(site_quarter_data)\n",
    "#     return missing_dates\n",
    "\n",
    "# # 统计每个站点各个季度的缺失天数\n",
    "# missing_days_per_site = []\n",
    "\n",
    "# for site in data['Site'].unique():\n",
    "#     site_data = data[data['Site'] == site]\n",
    "#     lat = site_data['Lat'].iloc[0]  # 获取站点纬度\n",
    "#     lon = site_data['Lon'].iloc[0]  # 获取站点经度\n",
    "\n",
    "#     for quarter, quarter_dates in quarters.items():\n",
    "#         missing_days = count_missing_dates(site_data, quarter_dates)\n",
    "#         missing_days_per_site.append([site, lon, lat, missing_days, quarter])\n",
    "\n",
    "# # 创建 DataFrame\n",
    "# missing_days_df = pd.DataFrame(missing_days_per_site, columns=['StationID', 'Lon', 'Lat', 'MissingDays', 'Period'])\n",
    "\n",
    "# # ...existing code...\n",
    "\n",
    "# # 保存结果到 CSV 文件\n",
    "# output_file_path = \"/backupdata/data_EPA/EQUATES/EQUATES_data/ds.input.aqs.o3.2011_MissingDays.csv\"\n",
    "# missing_days_df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # DiffForDayAndHour\n",
    "# # 定义时间段\n",
    "# periods = {\n",
    "#     'DJF': pd.date_range('2011-01-01', '2011-02-28').union(pd.date_range('2011-12-01', '2011-12-31')),\n",
    "#     'MAM': pd.date_range('2011-03-01', '2011-05-31'),\n",
    "#     'JJA': pd.date_range('2011-06-01', '2011-08-31'),\n",
    "#     'SON': pd.date_range('2011-09-01', '2011-11-30'),\n",
    "#     'Apr-Sep': pd.date_range('2011-04-01', '2011-09-30'),\n",
    "#     'Annual': pd.date_range('2011-01-01', '2011-12-31'),\n",
    "# }\n",
    "\n",
    "# # 读取小时数据表和日数据表\n",
    "# try:\n",
    "#     hourly_data = pd.read_csv('/backupdata/data_EPA/aq_obs/routine/2011/AQS_hourly_data_2011_LatLon.csv')\n",
    "#     daily_data = pd.read_csv('/backupdata/data_EPA/EQUATES/EQUATES_data/ds.input.aqs.o3.2011.csv')\n",
    "\n",
    "#     # 将小时数据的 'dateon' 列和日数据的 'Date' 列转换为 datetime 类型\n",
    "#     hourly_data['dateon'] = pd.to_datetime(hourly_data['dateon'])\n",
    "#     daily_data['Date'] = pd.to_datetime(daily_data['Date'])\n",
    "\n",
    "#     result = []\n",
    "\n",
    "#     for period_name, date_range in periods.items():\n",
    "#         # 筛选出该时间段内的小时数据和日数据\n",
    "#         hourly_period_data_isin = hourly_data[hourly_data['dateon'].isin(date_range)]\n",
    "#         daily_period_data_isin = daily_data[daily_data['Date'].isin(date_range)]\n",
    "\n",
    "#         hourly_period_data_logic = hourly_data[(hourly_data['dateon'] >= date_range.min()) & (hourly_data['dateon'] <= date_range.max())]\n",
    "#         daily_period_data_logic = daily_data[(daily_data['Date'] >= date_range.min()) & (daily_data['Date'] <= date_range.max())]\n",
    "\n",
    "#         # 统计每个站点在 isin 筛选后的记录数量\n",
    "#         hourly_site_counts_isin = hourly_period_data_isin.groupby('site_id').size()\n",
    "#         daily_site_counts_isin = daily_period_data_isin.groupby('Site').size()\n",
    "\n",
    "#         # 统计每个站点在逻辑判断筛选后的记录数量\n",
    "#         hourly_site_counts_logic = hourly_period_data_logic.groupby('site_id').size()\n",
    "#         daily_site_counts_logic = daily_period_data_logic.groupby('Site').size()\n",
    "\n",
    "#         print(f\"时间段 {period_name}：\")\n",
    "#         print(\"使用 isin 筛选 - 小时数据各站点记录数量统计：\")\n",
    "#         print(hourly_site_counts_isin)\n",
    "#         print(\"使用 isin 筛选 - 日数据各站点记录数量统计：\")\n",
    "#         print(daily_site_counts_isin)\n",
    "\n",
    "#         print(\"使用逻辑判断筛选 - 小时数据各站点记录数量统计：\")\n",
    "#         print(hourly_site_counts_logic)\n",
    "#         print(\"使用逻辑判断筛选 - 日数据各站点记录数量统计：\")\n",
    "#         print(daily_site_counts_logic)\n",
    "\n",
    "#         # 找出该时间段内小时数据和日数据中站点 ID 的差异\n",
    "#         diff_site_ids = set(hourly_period_data_isin['site_id']).symmetric_difference(set(daily_period_data_isin['Site']))\n",
    "\n",
    "#         # 获取差异站点 ID 的 Lat 和 Lon 信息\n",
    "#         for site_id in diff_site_ids:\n",
    "#             site_info = hourly_period_data_isin[hourly_period_data_isin['site_id'] == site_id].head(1)[['site_id', 'Lat', 'Lon']]\n",
    "#             if not site_info.empty:\n",
    "#                 site_info['Period'] = period_name\n",
    "#                 site_info['Flag'] = 2\n",
    "#             else:\n",
    "#                 site_info = daily_period_data_isin[daily_period_data_isin['Site'] == site_id].head(1)[['Site', 'Lat', 'Lon']]\n",
    "#                 site_info.rename(columns={'Site': 'site_id'}, inplace=True)\n",
    "#                 site_info['Period'] = period_name\n",
    "#                 site_info['Flag'] = 1\n",
    "#             result.append(site_info)\n",
    "\n",
    "#     # 合并结果\n",
    "#     result_df = pd.concat(result, ignore_index=True)\n",
    "\n",
    "#     # 输出结果到指定路径\n",
    "#     output_path = '/backupdata/data_EPA/aq_obs/routine/2011/2011_site_id_difference.csv'\n",
    "#     result_df.to_csv(output_path, index=False)\n",
    "#     print(f\"结果已保存到 {output_path}\")\n",
    "\n",
    "# except FileNotFoundError:\n",
    "#     print(\"文件未找到，请检查文件路径是否正确。\")\n",
    "# except Exception as e:\n",
    "#     print(f\"发生未知错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间段 DJF：\n",
      "小时数据的 Unique 站点个数: 813\n",
      "日数据的 Unique 站点个数: 799\n",
      "时间段 MAM：\n",
      "小时数据的 Unique 站点个数: 1301\n",
      "日数据的 Unique 站点个数: 1266\n",
      "时间段 JJA：\n",
      "小时数据的 Unique 站点个数: 1318\n",
      "日数据的 Unique 站点个数: 1285\n",
      "时间段 SON：\n",
      "小时数据的 Unique 站点个数: 1311\n",
      "日数据的 Unique 站点个数: 1279\n",
      "时间段 Apr-Sep：\n",
      "小时数据的 Unique 站点个数: 1322\n",
      "日数据的 Unique 站点个数: 1290\n",
      "时间段 Annual：\n",
      "小时数据的 Unique 站点个数: 1330\n",
      "日数据的 Unique 站点个数: 1299\n",
      "结果已保存到 /backupdata/data_EPA/aq_obs/routine/2011/2011_site_id_difference.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义时间段\n",
    "periods = {\n",
    "    'DJF': pd.date_range('2011-01-01', '2011-02-28').union(pd.date_range('2011-12-01', '2011-12-31')),\n",
    "    'MAM': pd.date_range('2011-03-01', '2011-05-31'),\n",
    "    'JJA': pd.date_range('2011-06-01', '2011-08-31'),\n",
    "    'SON': pd.date_range('2011-09-01', '2011-11-30'),\n",
    "    'Apr-Sep': pd.date_range('2011-04-01', '2011-09-30'),\n",
    "    'Annual': pd.date_range('2011-01-01', '2011-12-31'),\n",
    "}\n",
    "\n",
    "# 读取小时数据表和日数据表\n",
    "try:\n",
    "    hourly_data = pd.read_csv('/backupdata/data_EPA/aq_obs/routine/2011/AQS_hourly_data_2011_LatLon.csv')\n",
    "    daily_data = pd.read_csv('/backupdata/data_EPA/EQUATES/EQUATES_data/ds.input.aqs.o3.2011.csv')\n",
    "\n",
    "    # 将小时数据的 'dateon' 列和日数据的 'Date' 列转换为 datetime 类型\n",
    "    hourly_data['dateon'] = pd.to_datetime(hourly_data['dateon'])\n",
    "    daily_data['Date'] = pd.to_datetime(daily_data['Date'])\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for period_name, date_range in periods.items():\n",
    "        if period_name == 'DJF':\n",
    "            # 对于 DJF 时间段，分别处理两段日期范围\n",
    "            first_range = pd.date_range('2011-01-01', '2011-02-28')\n",
    "            second_range = pd.date_range('2011-12-01', '2011-12-31')\n",
    "            hourly_period_data = hourly_data[\n",
    "                ((hourly_data['dateon'] >= first_range.min()) & (hourly_data['dateon'] <= first_range.max())) |\n",
    "                ((hourly_data['dateon'] >= second_range.min()) & (hourly_data['dateon'] <= second_range.max()))\n",
    "            ]\n",
    "            daily_period_data = daily_data[\n",
    "                ((daily_data['Date'] >= first_range.min()) & (daily_data['Date'] <= first_range.max())) |\n",
    "                ((daily_data['Date'] >= second_range.min()) & (daily_data['Date'] <= second_range.max()))\n",
    "            ]\n",
    "        else:\n",
    "            # 其他时间段使用常规逻辑判断筛选\n",
    "            hourly_period_data = hourly_data[(hourly_data['dateon'] >= date_range.min()) & (hourly_data['dateon'] <= date_range.max())]\n",
    "            daily_period_data = daily_data[(daily_data['Date'] >= date_range.min()) & (daily_data['Date'] <= date_range.max())]\n",
    "\n",
    "        # 计算各个时间段各自的 Unique 站点个数\n",
    "        hourly_unique_count = len(set(hourly_period_data['site_id']))\n",
    "        daily_unique_count = len(set(daily_period_data['Site']))\n",
    "\n",
    "        print(f\"时间段 {period_name}：\")\n",
    "        print(f\"小时数据的 Unique 站点个数: {hourly_unique_count}\")\n",
    "        print(f\"日数据的 Unique 站点个数: {daily_unique_count}\")\n",
    "\n",
    "        # 找出该时间段内小时数据和日数据中站点 ID 的差异\n",
    "        diff_site_ids = set(hourly_period_data['site_id']).symmetric_difference(set(daily_period_data['Site']))\n",
    "\n",
    "        # 获取差异站点 ID 的 Lat 和 Lon 信息\n",
    "        for site_id in diff_site_ids:\n",
    "            site_info = hourly_period_data[hourly_period_data['site_id'] == site_id].head(1)[['site_id', 'Lat', 'Lon']]\n",
    "            if not site_info.empty:\n",
    "                site_info['Period'] = period_name\n",
    "                site_info['Flag'] = 2\n",
    "            else:\n",
    "                site_info = daily_period_data[daily_period_data['Site'] == site_id].head(1)[['Site', 'Lat', 'Lon']]\n",
    "                site_info.rename(columns={'Site': 'site_id'}, inplace=True)\n",
    "                site_info['Period'] = period_name\n",
    "                site_info['Flag'] = 1\n",
    "            result.append(site_info)\n",
    "\n",
    "    # 合并结果\n",
    "    result_df = pd.concat(result, ignore_index=True)\n",
    "\n",
    "    # 输出结果到指定路径\n",
    "    output_path = '/backupdata/data_EPA/aq_obs/routine/2011/2011_site_id_difference.csv'\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"结果已保存到 {output_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"文件未找到，请检查文件路径是否正确。\")\n",
    "except Exception as e:\n",
    "    print(f\"发生未知错误: {e}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
