{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: /DeepLearning/mnt/shixiansheng/data_fusion/output/2011_W126_CompareScatter\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Period'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/devin_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/devin_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/devin_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Period'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 257\u001b[0m\n\u001b[1;32m    254\u001b[0m x_axis_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/DeepLearning/mnt/shixiansheng/data_fusion/output/W126/2011_Monitor_W126_Compare.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m fusion_output_files:\n\u001b[0;32m--> 257\u001b[0m     \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_axis_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 240\u001b[0m, in \u001b[0;36mprocess_file\u001b[0;34m(fusion_output_file, x_axis_file)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m keywords:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_column, y_column \u001b[38;5;129;01min\u001b[39;00m comparisons:\n\u001b[0;32m--> 240\u001b[0m         \u001b[43mplot_density_scatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_data_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_data_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfusion_output_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m, in \u001b[0;36mplot_density_scatter\u001b[0;34m(dataframe_x, dataframe_y, x_column, y_column, period_column, output_dir, period_value, file_name, output_csv_path)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m绘制散点密度图：x_column vs y_column。\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m文件名包含对应的 Period 字段。\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 获取数据（通过关键字匹配 Period）\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m df_period_x \u001b[38;5;241m=\u001b[39m dataframe_x[\u001b[43mdataframe_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43mperiod_column\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(period_value, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m     65\u001b[0m df_period_y \u001b[38;5;241m=\u001b[39m dataframe_y[dataframe_y[period_column]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(period_value, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 如果数据为空，跳过\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/devin_env/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/devin_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Period'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde, linregress\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "\n",
    "# -------------------- 工具函数 --------------------\n",
    "def extract_key_period(period):\n",
    "    \"\"\"\n",
    "    Extract key period (e.g., JFM, AMJ) from the full period string.\n",
    "    \"\"\"\n",
    "    key_periods = [\"DJF\", \"MAM\", \"JJA\", \"SON\", 'Annual', 'Apr-Sep', 'top-10','W126']\n",
    "    for key in key_periods:\n",
    "        if key in period:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_year(filename):\n",
    "    \"\"\"\n",
    "    从文件名中提取年份（假设年份在 2011 - 2020 范围内）。\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(20[1-2][0-9])\", filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_axis_label(filename, variable):\n",
    "    \"\"\"\n",
    "    根据文件名和变量生成轴标签。\n",
    "    - 如果变量为 'model'，根据文件名判断是 'Harvard ML' 还是 'EQUATES'。\n",
    "    - 其他情况根据变量名确定标签，如 'vna_ozone' 对应 'VNA'。\n",
    "    \"\"\"\n",
    "    if 'model' in variable:\n",
    "        return \"EQUATES\"\n",
    "    elif \"harvard_ml\" in variable:\n",
    "        return \"Harvard ML\"\n",
    "    elif \"evna_ozone\" in variable:\n",
    "        return \"eVNA\"\n",
    "    elif \"avna_ozone\" in variable:\n",
    "        return \"aVNA\"\n",
    "    elif \"ds_ozone\" in variable:\n",
    "        return \"Downscaler\"\n",
    "    elif \"vna_ozone\" in variable:\n",
    "        return \"VNA\"\n",
    "    elif \"Conc\" in variable:\n",
    "        return \"Monitor\"\n",
    "    elif \"O3\" in variable:\n",
    "        return \"Monitor (Hourly)\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "# -------------------- 定义绘图函数 --------------------\n",
    "def plot_density_scatter(dataframe_x, dataframe_y, x_column, y_column, period_column, output_dir, period_value, file_name, output_csv_path):\n",
    "    \"\"\"\n",
    "    绘制散点密度图：x_column vs y_column。\n",
    "    文件名包含对应的 Period 字段。\n",
    "    \"\"\"\n",
    "    # 获取数据（通过关键字匹配 Period）\n",
    "    df_period_x = dataframe_x[dataframe_x[period_column].str.contains(period_value, case=False, na=False)]\n",
    "    df_period_y = dataframe_y[dataframe_y[period_column].str.contains(period_value, case=False, na=False)]\n",
    "\n",
    "    # 如果数据为空，跳过\n",
    "    if df_period_x.empty or df_period_y.empty:\n",
    "        print(f\"数据中没有有效数据，跳过 Period: {period_value} 的绘图。\")\n",
    "        return\n",
    "\n",
    "    # 获取数据\n",
    "    x_data = df_period_x[x_column].values\n",
    "    y_data = df_period_y[y_column].values\n",
    "\n",
    "    # 打印正在处理的数据信息\n",
    "    print(f\"正在处理文件: {file_name}, Period: {period_value}\")\n",
    "    print(f\"x_data 长度: {len(x_data)}, y_data 长度: {len(y_data)}\")\n",
    "    print(f\"x_data 前5个值: {x_data[:5]}\")\n",
    "    print(f\"y_data 前5个值: {y_data[:5]}\")\n",
    "    print(f\"x_data 中 NaN 的数量: {np.isnan(x_data).sum()}\")\n",
    "    print(f\"y_data 中 NaN 的数量: {np.isnan(y_data).sum()}\")\n",
    "\n",
    "    # 核密度计算\n",
    "    valid_indices = ~np.isnan(x_data) & ~np.isnan(y_data)\n",
    "    valid_x_data = x_data[valid_indices]\n",
    "    valid_y_data = y_data[valid_indices]\n",
    "\n",
    "    if len(valid_x_data) == 0 or len(valid_y_data) == 0:\n",
    "        print(f\"数据为空，跳过 Period: {period_value} 的绘图。\")\n",
    "        return\n",
    "\n",
    "    # 获取文件名的基名\n",
    "    file_base_name = os.path.basename(file_name).split(\".\")[0]\n",
    "\n",
    "    # 提取年份\n",
    "    year = get_year(file_name)\n",
    "\n",
    "    # 只提取季节和年份部分\n",
    "    period_search = extract_key_period(period_value)\n",
    "    if period_search:\n",
    "        period_value = period_search\n",
    "\n",
    "    # 拼接成期望的格式，如：2011_JAS\n",
    "    formatted_period = f\"{year}_{period_value}\"\n",
    "\n",
    "    # 生成轴标签\n",
    "    x_label = get_axis_label(x_axis_file, x_column)  # x 轴标签\n",
    "    y_label = get_axis_label(file_name, y_column)  # y 轴标签\n",
    "\n",
    "    full_title = f\"{formatted_period}: {y_label} vs. {x_label}\"\n",
    "\n",
    "    # 核密度计算\n",
    "    xy = np.vstack([valid_x_data, valid_y_data])\n",
    "    kde = gaussian_kde(xy)\n",
    "    z = kde(xy)\n",
    "    z = (z - z.min()) / (z.max() - z.min())  # 归一化\n",
    "\n",
    "    # 绘制散点密度图\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    scatter = ax.scatter(valid_x_data, valid_y_data, c=z, cmap='jet', s=20, alpha=0.8)\n",
    "    fig.colorbar(scatter, ax=ax)  # 删除了 label 参数\n",
    "\n",
    "    # 添加 1:1 参考线\n",
    "    max_val = max(valid_x_data.max(), valid_y_data.max())\n",
    "    # 调整x和y轴一样并添加余量，如果数据差别不大\n",
    "    max_val = 56\n",
    "    max_val1 = max_val + 3\n",
    "    ax.set_xlim(-3, max_val1)\n",
    "    ax.set_ylim(-3, max_val1)\n",
    "\n",
    "    ax.plot([-3, max_val1], [-3, max_val1], 'b--', lw=0.5)  # 蓝色 1:1 线\n",
    "\n",
    "    # 添加回归线\n",
    "    slope, intercept, r_value, _, _ = linregress(valid_x_data, valid_y_data)\n",
    "    r_squared = r_value ** 2\n",
    "    mb = np.mean(valid_y_data - valid_x_data)  # 计算 MB (平均偏差)\n",
    "\n",
    "    # 计算 RMSE\n",
    "    rmse = np.sqrt(np.mean((valid_y_data - valid_x_data) ** 2))  # 计算 RMSE\n",
    "\n",
    "    # 调整回归线方程格式\n",
    "    if intercept >= 0:\n",
    "        regression_equation = fr\"$y = {slope:.2f}\\it{{x}} + {intercept:.2f}$\"\n",
    "    else:\n",
    "        regression_equation = fr\"$y = {slope:.2f}\\it{{x}} {intercept:.2f}$\"\n",
    "\n",
    "    # 将 R²、MB、RMSE 和拟合直线方程添加到左上角\n",
    "    r_squared = round(r_squared, 2)\n",
    "    mb = round(mb, 2)\n",
    "    rmse = round(rmse, 2)\n",
    "\n",
    "    # 绘制回归线（红色）\n",
    "    regression_line = slope * np.array([0, max_val]) + intercept\n",
    "    ax.plot([0, max_val], regression_line, 'r-', lw=0.5, label=\"Regression Line\")\n",
    "    slope = round(slope, 2)\n",
    "    # 将统计信息添加到左上角\n",
    "    ax.text(0.05, 0.95, f\"$R^2$ = {r_squared:.2f}\\nMB = {mb}\\nRMSE = {rmse}\\n{regression_equation}\",\n",
    "            transform=ax.transAxes, ha=\"left\", va=\"top\", fontsize=12, fontname='Times New Roman', color='black')\n",
    "\n",
    "    # 设置标题和标签\n",
    "    ax.set_xlabel(x_label, fontsize=12, fontname='Times New Roman')  # x 轴标签\n",
    "    ax.set_ylabel(y_label, fontsize=12, fontname='Times New Roman')  # y 轴标签\n",
    "\n",
    "    # 将标题放置到图像顶部\n",
    "    fig.subplots_adjust(top=0.85)  # 调整标题的位置\n",
    "    ax.set_title(full_title, fontsize=13, loc='center', fontname='Times New Roman')\n",
    "\n",
    "    # 保存图像，文件名包含 Period 字段和输入文件名（不含路径）\n",
    "    output_file_name = f'{full_title}.png'\n",
    "    output_path = os.path.join(output_dir, output_file_name)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"散点密度图已保存至 {output_path}\")\n",
    "\n",
    "    # 将计算结果添加到表格中\n",
    "    variable_pair = f\"{y_label} vs. {x_label}\"\n",
    "    result_dict = {\n",
    "        'Variable Pair': variable_pair,\n",
    "        'Period': formatted_period,\n",
    "        'R_squared': r_squared,\n",
    "        'RMSE': rmse,\n",
    "        'MB': mb,\n",
    "        'Slope': slope,\n",
    "    }\n",
    "    result_df = pd.DataFrame([result_dict])\n",
    "    if not os.path.exists(output_csv_path):\n",
    "        result_df.to_csv(output_csv_path, index=False)\n",
    "    else:\n",
    "        result_df.to_csv(output_csv_path, mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "# -------------------- 读取和处理多个文件 --------------------\n",
    "def process_file(fusion_output_file, x_axis_file):\n",
    "    # 读取第一个文件的数据（y 轴数据）\n",
    "    df_data_y = pd.read_csv(fusion_output_file)\n",
    "\n",
    "    # 读取第二个文件的数据（x 轴数据）\n",
    "    df_data_x = pd.read_csv(x_axis_file)\n",
    "\n",
    "    # 提取Period列\n",
    "    period_column = 'Period'  # Period列\n",
    "\n",
    "    # variables = ['model', 'vna_ozone', 'evna_ozone', 'avna_ozone', 'ds_ozone', 'harvard_ml']\n",
    "    # variables = ['vna_ozone', 'evna_ozone', 'avna_ozone']\n",
    "    # comparisons = list(itertools.combinations(variables, 2))\n",
    "\n",
    "    comparisons = [('vna_ozone','vna_ozone')]\n",
    "    # comparisons = [('Conc','model'),('Conc','vna_ozone'),('Conc','evna_ozone'),('Conc','avna_ozone'),('Conc','ds_ozone')]\n",
    "    # print(comparisons)\n",
    "    # keywords = [\"DJF\", \"MAM\", \"JJA\", \"SON\", 'Annual', 'Apr-Sep', 'top-10','W126']\n",
    "    keywords = ['W126']\n",
    "\n",
    "    # 提取年份\n",
    "    year_x = get_year(x_axis_file)\n",
    "    year_y = get_year(fusion_output_file)\n",
    "\n",
    "    if year_x != year_y:\n",
    "        print(\"Warning: The years in the input files do not match!\")\n",
    "        return\n",
    "\n",
    "    year = year_x\n",
    "\n",
    "    # 动态生成路径名称\n",
    "    output_dir = os.path.join('/DeepLearning/mnt/shixiansheng/data_fusion/output', f\"{year}_W126_CompareScatter\")\n",
    "\n",
    "    # 如果路径不存在，则自动创建\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created directory: {output_dir}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {output_dir}\")\n",
    "\n",
    "    output_csv_path = os.path.join(output_dir, 'II.csv')\n",
    "\n",
    "    # 遍历每个关键字并绘制图形\n",
    "    for keyword in keywords:\n",
    "        for x_column, y_column in comparisons:\n",
    "            plot_density_scatter(df_data_x, df_data_y, x_column, y_column, period_column, output_dir, keyword,\n",
    "                                 fusion_output_file, output_csv_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件\n",
    "    # fusion_output_files = [\n",
    "    #     \"/DeepLearning/mnt/shixiansheng/data_fusion/output/2011_Data_WithoutCV/2011_SixDataset_CONUS_dailyIntometrics.csv\",\n",
    "    # ]\n",
    "    # x_axis_file = \"/DeepLearning/mnt/shixiansheng/data_fusion/output/2011_Data_WithoutCV/2011_SixDataset_CONUS_dailyIntometrics.csv\"\n",
    "\n",
    "    fusion_output_files = [\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/W126/2011_Monitor_W126_Compare.csv\",\n",
    "    ]\n",
    "    x_axis_file = \"/DeepLearning/mnt/shixiansheng/data_fusion/output/W126/2011_Monitor_W126_Compare.csv\"\n",
    "\n",
    "    for file in fusion_output_files:\n",
    "        process_file(file, x_axis_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
