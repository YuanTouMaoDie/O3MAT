{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理文件: /DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2002_Data_WithoutCV_Metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde, linregress\n",
    "import itertools\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------- 工具函数 --------------------\n",
    "def extract_key_period(period):\n",
    "    \"\"\"\n",
    "    Extract key period (e.g., JFM, AMJ) from the full period string.\n",
    "    \"\"\"\n",
    "    key_periods = [\"DJF\", \"MAM\", \"JJA\", \"SON\", 'Annual', 'Apr-Sep', 'top-10', 'W126']\n",
    "    for key in key_periods:\n",
    "        if key in period:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_year(filename):\n",
    "    \"\"\"\n",
    "    从文件名中提取年份（假设年份在 2000 - 2030 范围内）。\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(20[0-2][0-9])\", filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_axis_label(filename, variable):\n",
    "    \"\"\"\n",
    "    根据文件名和变量生成轴标签。\n",
    "    - 如果变量为 'model'，根据文件名判断是 'Harvard ML' 还是 'EQUATES'。\n",
    "    - 其他情况根据变量名确定标签，如 'vna_ozone' 对应 'VNA'。\n",
    "    \"\"\"\n",
    "    if 'model' in variable:\n",
    "        return \"EQUATES\"\n",
    "    elif \"harvard_ml\" in variable:\n",
    "        return \"Harvard ML\"\n",
    "    elif \"evna_ozone\" in variable:\n",
    "        return \"eVNA\"\n",
    "    elif \"avna_ozone\" in variable:\n",
    "        return \"aVNA\"\n",
    "    elif \"ds_ozone\" in variable:\n",
    "        return \"Downscaler\"\n",
    "    elif \"vna_ozone\" in variable:\n",
    "        return \"VNA\"\n",
    "    elif \"Conc\" in variable:\n",
    "        return \"Monitor\"\n",
    "    elif \"O3\" in variable:\n",
    "        return \"Monitor (Hourly)\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "# -------------------- 图片合并函数 --------------------\n",
    "def merge_images(image_paths, output_path, spacing=20):\n",
    "    \"\"\"\n",
    "    横向合并多张图片为一张图片，并设置图片之间的间距，用白色填充。\n",
    "\n",
    "    :param image_paths: 单张图片的路径列表\n",
    "    :param output_path: 合并后图片的保存路径\n",
    "    :param spacing: 图片之间的间距，单位为像素，默认为 20\n",
    "    \"\"\"\n",
    "    # 读取所有图片\n",
    "    images = [Image.open(path) for path in image_paths]\n",
    "\n",
    "    # 获取图片的宽度和高度\n",
    "    width, height = images[0].size\n",
    "\n",
    "    # 计算合并后图片的总宽度，考虑间距\n",
    "    total_width = width * len(images) + spacing * (len(images) - 1)\n",
    "\n",
    "    # 创建合并图片，宽度为所有图片宽度与间距之和，高度为单张图片的高度\n",
    "    merged_image = Image.new('RGB', (total_width, height), color='white')\n",
    "\n",
    "    # 粘贴每张图片到合并图片的对应位置，并添加间距\n",
    "    current_x = 0\n",
    "    for i, image in enumerate(images):\n",
    "        merged_image.paste(image, (current_x, 0))\n",
    "        current_x += width + spacing\n",
    "\n",
    "    # 保存合并图片\n",
    "    merged_image.save(output_path)\n",
    "    print(f\"合并图片已保存到 {output_path}\")\n",
    "\n",
    "\n",
    "# -------------------- 定义绘图函数 --------------------\n",
    "def plot_density_scatter(dataframe_x, dataframe_y, x_column, y_column, period_column, output_dir_base, year, period_value, x_axis_filename, y_axis_filename, output_csv_path, default_range=None, top10_range=None, top10_special_years=None):\n",
    "    \"\"\"\n",
    "    绘制散点密度图：x_column vs y_column。\n",
    "    文件名包含对应的 Period 字段。\n",
    "    \"\"\"\n",
    "    # 获取数据（通过关键字匹配 Period）\n",
    "    df_period_x = dataframe_x[dataframe_x[period_column].str.contains(period_value, case=False, na=False)]\n",
    "    df_period_y = dataframe_y[dataframe_y[period_column].str.contains(period_value, case=False, na=False)]\n",
    "\n",
    "    # 如果数据为空，跳过\n",
    "    if df_period_x.empty or df_period_y.empty:\n",
    "        print(f\"数据中没有有效数据，跳过 Period: {period_value} 的绘图。\")\n",
    "        return\n",
    "\n",
    "    # 获取数据\n",
    "    x_data = df_period_x[x_column].values\n",
    "    y_data = df_period_y[y_column].values\n",
    "\n",
    "    # 打印正在处理的数据信息\n",
    "    print(f\"正在处理文件: {y_axis_filename}, Period: {period_value}\")\n",
    "    print(f\"x_data 长度: {len(x_data)}, y_data 长度: {len(y_data)}\")\n",
    "    print(f\"x_data 前5个值: {x_data[:5]}\")\n",
    "    print(f\"y_data 前5个值: {y_data[:5]}\")\n",
    "    print(f\"x_data 中 NaN 的数量: {np.isnan(x_data).sum()}\")\n",
    "    print(f\"y_data 中 NaN 的数量: {np.isnan(y_data).sum()}\")\n",
    "\n",
    "    # 核密度计算\n",
    "    valid_indices = ~np.isnan(x_data) & ~np.isnan(y_data)\n",
    "    valid_x_data = x_data[valid_indices]\n",
    "    valid_y_data = y_data[valid_indices]\n",
    "\n",
    "    if len(valid_x_data) == 0 or len(valid_y_data) == 0:\n",
    "        print(f\"数据为空，跳过 Period: {period_value} 的绘图。\")\n",
    "        return\n",
    "\n",
    "    # 只提取季节和年份部分\n",
    "    period_search = extract_key_period(period_value)\n",
    "    if period_search:\n",
    "        period_value = period_search\n",
    "\n",
    "    # 拼接成期望的格式，如：2011_JAS\n",
    "    formatted_period = f\"{year}_{period_value}\"\n",
    "\n",
    "    # 生成轴标签\n",
    "    x_label = get_axis_label(x_axis_filename, x_column)  # x 轴标签\n",
    "    y_label = get_axis_label(y_axis_filename, y_column)  # y 轴标签\n",
    "\n",
    "    full_title = f\"{formatted_period}: {y_label} vs. {x_label}\"\n",
    "\n",
    "    # 核密度计算\n",
    "    xy = np.vstack([valid_x_data, valid_y_data])\n",
    "    kde = gaussian_kde(xy)\n",
    "    z = kde(xy)\n",
    "    z = (z - z.min()) / (z.max() - z.min())  # 归一化\n",
    "\n",
    "    # 绘制散点密度图\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    scatter = ax.scatter(valid_x_data, valid_y_data, c=z, cmap='jet', s=20, alpha=0.8)\n",
    "    fig.colorbar(scatter, ax=ax)  # 删除了 label 参数\n",
    "\n",
    "    # -------------------- 坐标轴范围设置 --------------------\n",
    "    if period_value == 'top-10' and top10_range:\n",
    "        # top-10 周期的特殊处理\n",
    "        if top10_special_years and year in top10_special_years:\n",
    "            # 特殊年份的特殊范围\n",
    "            ax.set_xlim(top10_special_years[year])\n",
    "            ax.set_ylim(top10_special_years[year])\n",
    "            print(f\"使用 top-10 特殊年份设置的坐标轴范围: {top10_special_years[year]} for {year}\")\n",
    "        else:\n",
    "            # top-10 周期的默认范围\n",
    "            ax.set_xlim(top10_range)\n",
    "            ax.set_ylim(top10_range)\n",
    "            print(f\"使用 top-10 默认坐标轴范围: {top10_range}\")\n",
    "    else:\n",
    "        # 其他周期使用统一的默认范围\n",
    "        if default_range:\n",
    "            ax.set_xlim(default_range)\n",
    "            ax.set_ylim(default_range)\n",
    "            print(f\"使用默认坐标轴范围: {default_range}\")\n",
    "        else:\n",
    "            # 如果未提供默认范围，使用原逻辑\n",
    "            max_val = max(valid_x_data.max(), valid_y_data.max())\n",
    "            max_val = 65  # 原代码中的固定值\n",
    "            max_val1 = max_val + 3\n",
    "            ax.set_xlim(-3, max_val1)\n",
    "            ax.set_ylim(-3, max_val1)\n",
    "            print(f\"使用原始默认坐标轴范围: (-3, {max_val1})\")\n",
    "\n",
    "    # 确保1:1线适应新的坐标轴范围\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    ax.plot([x_min, x_max], [x_min, x_max], 'b--', lw=0.5)  # 蓝色 1:1 线\n",
    "\n",
    "    # 添加回归线\n",
    "    slope, intercept, r_value, _, _ = linregress(valid_x_data, valid_y_data)\n",
    "    r_squared = r_value ** 2\n",
    "    mb = np.mean(valid_y_data - valid_x_data)  # 计算 MB (平均偏差)\n",
    "\n",
    "    # 计算 RMSE\n",
    "    rmse = np.sqrt(np.mean((valid_y_data - valid_x_data) ** 2))  # 计算 RMSE\n",
    "\n",
    "    # 调整回归线方程格式\n",
    "    if intercept >= 0:\n",
    "        regression_equation = fr\"$y = {slope:.2f}\\it{{x}} + {intercept:.2f}$\"\n",
    "    else:\n",
    "        regression_equation = fr\"$y = {slope:.2f}\\it{{x}} {intercept:.2f}$\"\n",
    "\n",
    "    # 将 R²、MB、RMSE 和拟合直线方程添加到左上角\n",
    "    r_squared = round(r_squared, 2)\n",
    "    mb = round(mb, 2)\n",
    "    rmse = round(rmse, 2)\n",
    "\n",
    "    # 绘制回归线（红色）\n",
    "    regression_line = slope * np.array([x_min, x_max]) + intercept\n",
    "    ax.plot([x_min, x_max], regression_line, 'r-', lw=0.5, label=\"Regression Line\")\n",
    "    slope = round(slope, 2)\n",
    "    \n",
    "    # 将统计信息添加到左上角\n",
    "    ax.text(0.05, 0.95, f\"$R^2$ = {r_squared:.2f}\\nMB = {mb}\\nRMSE = {rmse}\\n{regression_equation}\",\n",
    "            transform=ax.transAxes, ha=\"left\", va=\"top\", fontsize=12, fontname='Times New Roman', color='black')\n",
    "\n",
    "    # 设置标题和标签\n",
    "    ax.set_xlabel(x_label, fontsize=12, fontname='Times New Roman')  # x 轴标签\n",
    "    ax.set_ylabel(y_label, fontsize=12, fontname='Times New Roman')  # y 轴标签\n",
    "\n",
    "    # 将标题放置到图像顶部\n",
    "    fig.subplots_adjust(top=0.85)  # 调整标题的位置\n",
    "    ax.set_title(full_title, fontsize=13, loc='center', fontname='Times New Roman')\n",
    "\n",
    "    # -------------------- 修改：输出路径 --------------------\n",
    "    # 创建年份文件夹（如 2011_CompareScatter）\n",
    "    year_folder = f\"{year}_CompareScatter\"\n",
    "    output_dir = os.path.join(output_dir_base, year_folder)\n",
    "    \n",
    "    # 如果路径不存在，则自动创建\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"创建年份文件夹: {output_dir}\")\n",
    "    \n",
    "    # 保存图像，文件名包含 Period 字段和输入文件名（不含路径）\n",
    "    output_file_name = f'{full_title}.png'\n",
    "    output_path = os.path.join(output_dir, output_file_name)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close(fig)  # 关闭图形以释放内存\n",
    "    print(f\"散点密度图已保存至 {output_path}\")\n",
    "\n",
    "    # 返回保存的图片路径，用于后续合并\n",
    "    return output_path, formatted_period, (x_column, y_column)\n",
    "\n",
    "\n",
    "# -------------------- 按周期和组合并图片 --------------------\n",
    "def merge_images_by_period_and_group(all_period_images, output_dir, groups, spacing=20):\n",
    "    \"\"\"\n",
    "    按周期和指定的变量组合并图片\n",
    "    \n",
    "    :param all_period_images: 所有图片信息，按周期分组\n",
    "    :param output_dir: 输出目录\n",
    "    :param groups: 定义的变量组\n",
    "    :param spacing: 图片间距\n",
    "    \"\"\"\n",
    "    # 为每个组创建一个文件夹\n",
    "    for group_idx, group in enumerate(groups):\n",
    "        group_dir = os.path.join(output_dir, f\"Group_{group_idx+1}\")\n",
    "        if not os.path.exists(group_dir):\n",
    "            os.makedirs(group_dir)\n",
    "            print(f\"创建组文件夹: {group_dir}\")\n",
    "        \n",
    "        # 按周期处理\n",
    "        for period, image_info_list in all_period_images.items():\n",
    "            # 筛选属于当前组的图片\n",
    "            group_images = []\n",
    "            for info in image_info_list:\n",
    "                path, year, (x_col, y_col) = info\n",
    "                # 检查这对变量是否在当前组中\n",
    "                if (x_col, y_col) in group or (y_col, x_col) in group:\n",
    "                    group_images.append(info)\n",
    "            \n",
    "            # 如果找到了属于该组的图片，则合并它们\n",
    "            if group_images:\n",
    "                image_paths = [info[0] for info in group_images]\n",
    "                # 生成组名\n",
    "                group_name = \"_vs_\".join([f\"{get_axis_label('', pair[0])}_{get_axis_label('', pair[1])}\" for pair in group])\n",
    "                output_path = os.path.join(group_dir, f\"Merged_{period}_{group_name}.png\")\n",
    "                \n",
    "                print(f\"正在合并 {period} 的组 {group_idx+1} 图片: {image_paths}\")\n",
    "                merge_images(image_paths, output_path, spacing=spacing)\n",
    "\n",
    "\n",
    "# -------------------- 读取和处理多个文件 --------------------\n",
    "def process_file(fusion_output_file, x_axis_file, all_period_images=None, default_range=None, top10_range=None, top10_special_years=None):\n",
    "    # 读取第一个文件的数据（y 轴数据）\n",
    "    df_data_y = pd.read_csv(fusion_output_file)\n",
    "\n",
    "    # 读取第二个文件的数据（x 轴数据）\n",
    "    df_data_x = pd.read_csv(x_axis_file)\n",
    "\n",
    "    # 提取年份\n",
    "    year = get_year(fusion_output_file)\n",
    "    if not year:\n",
    "        print(f\"无法从文件名 {fusion_output_file} 中提取年份，跳过处理\")\n",
    "        return\n",
    "\n",
    "    # 提取Period列\n",
    "    period_column = 'Period'  # Period列\n",
    "\n",
    "    variables = ['model', 'vna_ozone', 'evna_ozone', 'avna_ozone', 'ds_ozone', 'harvard_ml']\n",
    "    comparisons = list(itertools.combinations(variables, 2))\n",
    "\n",
    "    keywords = [\"SON\", 'Annual', 'Apr-Sep', 'top-10']\n",
    "    # keywords = ['top-10']\n",
    "\n",
    "    # 动态生成基础输出路径\n",
    "    output_dir_base = \"/DeepLearning/mnt/shixiansheng/data_fusion/output/CompareScatter\"\n",
    "\n",
    "    # 如果基础路径不存在，则自动创建\n",
    "    if not os.path.exists(output_dir_base):\n",
    "        os.makedirs(output_dir_base)\n",
    "        print(f\"创建基础输出目录: {output_dir_base}\")\n",
    "\n",
    "    output_csv_path = os.path.join(output_dir_base, 'Metrics.csv')\n",
    "\n",
    "    # 用于存储该文件生成的所有图片路径，按周期分组\n",
    "    file_period_images = {}\n",
    "\n",
    "    # 遍历每个关键字并绘制图形\n",
    "    for keyword in keywords:\n",
    "        for x_column, y_column in comparisons:\n",
    "            image_path = plot_density_scatter(\n",
    "                df_data_x, df_data_y, x_column, y_column, period_column, \n",
    "                output_dir_base, year, keyword, x_axis_file, fusion_output_file, output_csv_path,\n",
    "                default_range=default_range,\n",
    "                top10_range=top10_range,\n",
    "                top10_special_years=top10_special_years\n",
    "            )\n",
    "\n",
    "            if image_path:\n",
    "                path, period, var_pair = image_path\n",
    "                # 将图片路径添加到按周期分组的字典中\n",
    "                if period not in file_period_images:\n",
    "                    file_period_images[period] = []\n",
    "                file_period_images[period].append((path, year, var_pair))\n",
    "\n",
    "                # 如果提供了全局存储字典，则也添加到其中\n",
    "                if all_period_images is not None:\n",
    "                    if period not in all_period_images:\n",
    "                        all_period_images[period] = []\n",
    "                    all_period_images[period].append((path, year, var_pair))\n",
    "\n",
    "    # 返回该文件生成的图片信息\n",
    "    return file_period_images\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件列表（多年数据）\n",
    "    fusion_output_files = [\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2003_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2004_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2005_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2006_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2007_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2008_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2009_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2010_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2011_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2012_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2013_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2014_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2015_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2016_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2017_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2018_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2019_Data_WithoutCV_Metrics.csv\",\n",
    "        # 添加更多年份的文件...\n",
    "    ]\n",
    "\n",
    "    # 对应的x轴文件列表（与fusion_output_files一一对应）\n",
    "    x_axis_files = [\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2003_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2004_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2005_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2006_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2007_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2008_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2009_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2010_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2011_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2012_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2013_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2014_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2015_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2016_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2017_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2018_Data_WithoutCV_Metrics.csv\",\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output/DailyData_WithoutCV/2019_Data_WithoutCV_Metrics.csv\",\n",
    "        # 添加更多年份的文件...\n",
    "    ]\n",
    "\n",
    "    # 用于存储所有年份、所有周期的图片路径\n",
    "    all_period_images = {}\n",
    "\n",
    "    # -------------------- 定义坐标轴范围 --------------------\n",
    "    # 所有周期的默认范围（除了top-10）\n",
    "    default_range = (-3, 98)  # 与原代码逻辑一致\n",
    "    \n",
    "    # top-10 周期的默认范围\n",
    "    top10_range = (-3, 143)\n",
    "    \n",
    "    # top-10 周期中特殊年份的范围\n",
    "    top10_special_years = {\n",
    "        '2002': (-3, 233),  # 2012年的特殊范围\n",
    "        '2003': (-3, 233),\n",
    "        '2004': (-3, 233),\n",
    "        '2005': (-3, 233),\n",
    "        '2006': (-3, 233),\n",
    "        '2007': (-3, 233),\n",
    "        '2009': (-3, 233),     # 2013年的特殊范围\n",
    "    }\n",
    "\n",
    "    # 处理每个文件\n",
    "    for fusion_file, x_file in zip(fusion_output_files, x_axis_files):\n",
    "        print(f\"\\n处理文件: {fusion_file}\")\n",
    "        process_file(\n",
    "            fusion_file, x_file, all_period_images,\n",
    "            default_range=default_range,\n",
    "            top10_range=top10_range,\n",
    "            top10_special_years=top10_special_years\n",
    "        )\n",
    "\n",
    "    # 创建合并图片的输出目录\n",
    "    merged_output_dir = os.path.join('/DeepLearning/mnt/shixiansheng/data_fusion/output', \"Merged_Scatter\")\n",
    "    if not os.path.exists(merged_output_dir):\n",
    "        os.makedirs(merged_output_dir)\n",
    "        print(f\"创建合并图片目录: {merged_output_dir}\")\n",
    "\n",
    "    # 定义合并组\n",
    "    groups = [\n",
    "        [('model','vna_ozone'), ('model','evna_ozone'), ('model','avna_ozone'), ('model','ds_ozone'), ('model','harvard_ml')],\n",
    "        [('vna_ozone', 'evna_ozone'), ('vna_ozone', 'avna_ozone'), ('vna_ozone', 'ds_ozone'), ('vna_ozone', 'harvard_ml'), ('ds_ozone', 'harvard_ml')],\n",
    "        [('evna_ozone', 'avna_ozone'), ('evna_ozone', 'ds_ozone'), ('evna_ozone', 'harvard_ml'), ('avna_ozone', 'ds_ozone'), ('avna_ozone', 'harvard_ml')]\n",
    "    ]\n",
    "\n",
    "    # 按周期和组合并图片\n",
    "    merge_images_by_period_and_group(all_period_images, merged_output_dir, groups, spacing=30)\n",
    "\n",
    "    print(\"所有图片处理和合并完成！\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
