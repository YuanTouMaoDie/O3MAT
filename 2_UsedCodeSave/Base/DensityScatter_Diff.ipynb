{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde, linregress\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# -------------------- 工具函数 --------------------\n",
    "def extract_key_period(period):\n",
    "    \"\"\"\n",
    "    Extract key period (e.g., JFM, AMJ) from the full period string.\n",
    "    \"\"\"\n",
    "    key_periods = [\"DJF\", \"MAM\", \"JJA\", \"SON\", 'Annual', 'Apr-Sep', 'top-10', '98th']\n",
    "    for key in key_periods:\n",
    "        if key in period:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def get_year(filename):\n",
    "    \"\"\"\n",
    "    从文件名中提取年份（假设年份在 2011 - 2020 范围内）。\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(20[1-2][0-9])\", filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def get_axis_label(filename, variable):\n",
    "    \"\"\"\n",
    "    根据文件名和变量生成轴标签。\n",
    "    - 如果变量为 'model'，根据文件名判断是 'Harvard ML' 还是 'EQUATES'。\n",
    "    - 其他情况根据变量名确定标签，如 'vna_ozone' 对应 'VNA'。\n",
    "    \"\"\"\n",
    "    if variable =='model':\n",
    "        return \"EQUATES\"\n",
    "    elif \"harvard_ml\" in filename:\n",
    "        return \"Harvard ML\"\n",
    "    elif \"vna_ozone\" in variable:\n",
    "        return \"VNA\"\n",
    "    elif \"evna_ozone\" in variable:\n",
    "        return \"eVNA\"\n",
    "    elif \"avna_ozone\" in variable:\n",
    "        return \"aVNA\"\n",
    "    elif \"ds_ozone\" in variable:\n",
    "        return \"Downscaler\"\n",
    "    return \"unknown\"\n",
    "\n",
    "# -------------------- 定义绘图函数 --------------------\n",
    "def plot_density_scatter(dataframe_x, dataframe_y, x_column, y_column, period_column, output_dir, period_value, file_name):\n",
    "    \"\"\"\n",
    "    绘制散点密度图：x_column vs y_column。\n",
    "    文件名包含对应的 Period 字段。\n",
    "    \"\"\"\n",
    "    # 获取数据（通过关键字匹配 Period）\n",
    "    df_period_x = dataframe_x[dataframe_x[period_column].str.contains(period_value, case=False, na=False)]\n",
    "    df_period_y = dataframe_y[dataframe_y[period_column].str.contains(period_value, case=False, na=False)]\n",
    "\n",
    "    # 如果数据为空，跳过\n",
    "    if df_period_x.empty or df_period_y.empty:\n",
    "        print(f\"数据中没有有效数据，跳过 Period: {period_value} 的绘图。\")\n",
    "        return\n",
    "\n",
    "    # 获取数据\n",
    "    x_data = df_period_x[x_column].values\n",
    "    y_data = df_period_y[y_column].values\n",
    "\n",
    "    # 打印正在处理的数据信息\n",
    "    print(f\"正在处理文件: {file_name}, Period: {period_value}\")\n",
    "    print(f\"x_data 长度: {len(x_data)}, y_data 长度: {len(y_data)}\")\n",
    "    print(f\"x_data 前5个值: {x_data[:5]}\")\n",
    "    print(f\"y_data 前5个值: {y_data[:5]}\")\n",
    "    print(f\"x_data 中 NaN 的数量: {np.isnan(x_data).sum()}\")\n",
    "    print(f\"y_data 中 NaN 的数量: {np.isnan(y_data).sum()}\")\n",
    "\n",
    "    # 核密度计算\n",
    "    valid_indices = ~np.isnan(x_data) & ~np.isnan(y_data)\n",
    "    valid_x_data = x_data[valid_indices]\n",
    "    valid_y_data = y_data[valid_indices]\n",
    "\n",
    "    if len(valid_x_data) == 0 or len(valid_y_data) == 0:\n",
    "        print(f\"数据为空，跳过 Period: {period_value} 的绘图。\")\n",
    "        return\n",
    "\n",
    "    # 获取文件名的基名\n",
    "    file_base_name = os.path.basename(file_name).split(\".\")[0]\n",
    "\n",
    "    # 提取年份\n",
    "    year = get_year(file_name)\n",
    "\n",
    "    # 只提取季节和年份部分\n",
    "    period_search = extract_key_period(period_value)\n",
    "    if period_search:\n",
    "        period_value = period_search\n",
    "\n",
    "    # 拼接成期望的格式，如：2011_JAS\n",
    "    formatted_period = f\"{year}_{period_value}\"\n",
    "\n",
    "    # 生成轴标签\n",
    "    x_label = get_axis_label(x_axis_file, x_column)  # x 轴标签\n",
    "    y_label = get_axis_label(file_name, y_column)    # y 轴标签\n",
    "\n",
    "    full_title = f\"{formatted_period}: {y_label} vs. {x_label}\"\n",
    "\n",
    "    # 核密度计算\n",
    "    xy = np.vstack([valid_x_data, valid_y_data])\n",
    "    kde = gaussian_kde(xy)\n",
    "    z = kde(xy)\n",
    "    z = (z - z.min()) / (z.max() - z.min())  # 归一化\n",
    "\n",
    "    # 绘制散点密度图\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    scatter = ax.scatter(valid_x_data, valid_y_data, c=z, cmap='jet', s=20, alpha=0.8)\n",
    "    fig.colorbar(scatter, ax=ax)  # 删除了 label 参数\n",
    "\n",
    "    # 添加 1:1 参考线\n",
    "    max_val = max(valid_x_data.max(), valid_y_data.max())\n",
    "\n",
    "    # 调整x和y轴一样并添加余量，如果数据差别不大\n",
    "    max_val1 = max_val + 3\n",
    "    ax.set_xlim(-3, max_val1)\n",
    "    ax.set_ylim(-3, max_val1)\n",
    "\n",
    "    ax.plot([0, max_val], [0, max_val], 'k-', lw=0.5, label=\"1:1 line\")\n",
    "\n",
    "    # 添加回归线\n",
    "    slope, intercept, r_value, _, _ = linregress(valid_x_data, valid_y_data)\n",
    "    regression_line = slope * np.array([0, max_val]) + intercept\n",
    "    ax.plot([0, max_val], regression_line, 'r-', lw=0.5, label=\"Regression Line\")\n",
    "    r_squared = r_value ** 2\n",
    "    mae = np.mean(np.abs(valid_y_data - valid_x_data))  # 计算 MAE\n",
    "    rmse = np.sqrt(np.mean((valid_y_data - valid_x_data) ** 2))  # 计算 RMSE\n",
    "    print(f\"RMSE: {rmse}, MAE: {mae}\")\n",
    "    ax.text(0.95, 0.05, f\"$R^2$ = {r_squared:.4f}\\nMAE = {mae:.3f}\\nRMSE = {rmse:.3f}\",\n",
    "            transform=ax.transAxes, ha=\"right\", va=\"bottom\", fontsize=12)\n",
    "\n",
    "    # 设置标题和标签\n",
    "    ax.set_xlabel(x_label, fontsize=12)  # x 轴标签\n",
    "    ax.set_ylabel(y_label, fontsize=12)  # y 轴标签\n",
    "    ax.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "    # 将标题放置到图像顶部\n",
    "    fig.subplots_adjust(top=0.85)  # 调整标题的位置\n",
    "    ax.set_title(full_title, fontsize=13, loc='center')\n",
    "\n",
    "    # 保存图像，文件名包含 Period 字段和输入文件名（不含路径）\n",
    "    output_file_name = f'{file_base_name}_{formatted_period}_{y_column}_vs_{x_column}_density.png'\n",
    "    output_path = os.path.join(output_dir, output_file_name)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"散点密度图已保存至 {output_path}\")\n",
    "\n",
    "# -------------------- 读取和处理多个文件 --------------------\n",
    "def process_file(fusion_output_file, x_axis_file):\n",
    "    # 读取第一个文件的数据（y 轴数据）\n",
    "    df_data_y = pd.read_csv(fusion_output_file)\n",
    "\n",
    "    # 读取第二个文件的数据（x 轴数据）\n",
    "    df_data_x = pd.read_csv(x_axis_file)\n",
    "\n",
    "    # 提取Period列\n",
    "    period_column = 'Period'  # Period列\n",
    "\n",
    "    variables = ['model','vna_ozone', 'evna_ozone', 'avna_ozone', 'ds_ozone','harvard_ml']\n",
    "    comparisons = list(itertools.combinations(variables, 2))\n",
    "\n",
    "    # 定义需要匹配的关键字（如 JFM, AMJ, JAS, OND 等）\n",
    "    keywords = [\"DJF\", \"MAM\", \"JJA\", \"SON\", 'Annual', 'Apr-Sep', 'top-10', '98th']\n",
    "\n",
    "    # 提取年份\n",
    "    year_x = get_year(x_axis_file)\n",
    "    year_y = get_year(fusion_output_file)\n",
    "\n",
    "    if year_x != year_y:\n",
    "        print(\"Warning: The years in the input files do not match!\")\n",
    "        return\n",
    "\n",
    "    year = year_x\n",
    "\n",
    "    # 动态生成路径名称\n",
    "    output_dir = os.path.join('/DeepLearning/mnt/shixiansheng/data_fusion/output', f\"{year}_CompareScatter\")\n",
    "\n",
    "    # 如果路径不存在，则自动创建\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Created directory: {output_dir}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {output_dir}\")\n",
    "\n",
    "    # 遍历每个关键字并绘制图形\n",
    "    for keyword in keywords:\n",
    "        for x_column, y_column in comparisons:\n",
    "            plot_density_scatter(df_data_x, df_data_y, x_column, y_column, period_column, output_dir, keyword, fusion_output_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件\n",
    "    fusion_output_files = [\n",
    "        \"/DeepLearning/mnt/shixiansheng/data_fusion/output//BarronScript_ALL_2011_FtAIndex_InUSA.csv\",\n",
    "    ]\n",
    "    x_axis_file = \"/DeepLearning/mnt/shixiansheng/data_fusion/output//BarronResult_VNAeVNA_2011_FtAIndex_InUSA.csv\"\n",
    "\n",
    "    for file in fusion_output_files:\n",
    "        process_file(file, x_axis_file)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
